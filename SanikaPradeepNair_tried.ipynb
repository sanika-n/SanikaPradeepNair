{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea38ee8-16b9-4ea1-bb61-e972309e92e3",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee64daf7-423a-4389-82f2-4153369f74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0674bdc-3b55-4811-9c69-a50e5a5c219d",
   "metadata": {},
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192b6b16-c968-4af9-a015-5d0b1e4a60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_dataset.csv\") \n",
    "\n",
    "newdf = pd.DataFrame(columns=['id', 'numpy', 'emotion'])\n",
    "\n",
    "s=[]\n",
    "pixels = df.iloc[:, 1].to_numpy() #converting the second column to a numpy array\n",
    "\n",
    "for i in pixels:\n",
    "    number_list = i.split()\n",
    "    number_list = [int(num) for num in number_list]\n",
    "    s.append(number_list)\n",
    "s=np.array(s)\n",
    "#s is a 2d array containing all the images in an array format\n",
    "emotion=df.iloc[:, 2].to_numpy()\n",
    "\n",
    "\n",
    "#data augmentation\n",
    "#changing contrast\n",
    "#changing brightness\n",
    "counter=0\n",
    "for i in range(s.shape[0]):\n",
    "    image = s[i].reshape((48,48))\n",
    "    brightness = 20 \n",
    "    contrast = 100\n",
    "    image2 = cv2.addWeighted(image, contrast, np.zeros(image.shape, image.dtype), 0, brightness) \n",
    "    image3 = cv2.flip(image, 1)\n",
    "    image=image.reshape((2304,))\n",
    "    image2=image2.reshape((2304,))\n",
    "    image3=image3.reshape((2304,))\n",
    "    newdf.loc[counter] = [counter, image, emotion[i]]\n",
    "    counter+=1\n",
    "    newdf.loc[counter] = [counter, image2, emotion[i]]\n",
    "    counter+=1\n",
    "    newdf.loc[counter] = [counter, image3, emotion[i]]\n",
    "    counter+=1\n",
    "\n",
    "\n",
    "id= newdf.iloc[:, 0].to_numpy() #converting the first column of df into a numpy array id\n",
    "emotion=newdf.iloc[:, 2].to_numpy()\n",
    "s=[]\n",
    "for i in range(15000):\n",
    "    s.append(newdf.iloc[i]['numpy'])\n",
    "s=np.array(s)#updated s, contianing the array representation of the augmented data as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7675bd-fcb9-4eb5-86bc-17657a8b33bf",
   "metadata": {},
   "source": [
    "Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba31d0a-ea13-4a57-a1bf-df4bcd56622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "model = Sequential(\n",
    "    [               \n",
    "        \n",
    "        tf.keras.layers.InputLayer((2304,)),\n",
    "        tf.keras.layers.Dense(20, activation=\"relu\", name=\"L1\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\", name=\"L2\"),\n",
    "        tf.keras.layers.Dense(7, activation=\"linear\", name=\"L3\")\n",
    "       \n",
    "    ], name = \"my_model\" \n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb3a90-be51-44fb-86d8-086be37ee7f3",
   "metadata": {},
   "source": [
    "Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000a3734-6ecb-4822-ba62-c3d3749b75b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 272.3691\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8625\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8340\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8212\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8145\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8105\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.8082\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8067\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8058\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c6c1242cc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    s,emotion,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186b6190-90d3-468f-a53e-2e8d95c8dc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "dff = pd.read_csv(\"train_dataset.csv\") \n",
    "idd= dff.iloc[:, 0].to_numpy() #converting the first column of df into a numpy array id\n",
    "ss=[]\n",
    "pixelss = dff.iloc[:, 1].to_numpy() #converting the second column to a numpy array\n",
    "for i in pixelss:\n",
    "    number_list = i.split()\n",
    "    number_list = [int(num) for num in number_list]\n",
    "    ss.append(number_list)\n",
    "ss=np.array(ss)\n",
    "#ss is the numpy array containing the info about all the test images\n",
    "y_pred = model.predict(ss)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "#creating a new data-frame which can be converted to csv for submission\n",
    "fdf=pd.DataFrame()\n",
    "se = pd.Series(idd)\n",
    "fdf['id'] = se.values\n",
    "see=pd.Series(y_pred)\n",
    "fdf['emotion']=see.values\n",
    "fdf.to_csv('failed_results.csv',index=False)#I deleted the file that was created after running this, so to see the result of this pls run this block again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3f74f-3974-406d-bde7-283de870da40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
